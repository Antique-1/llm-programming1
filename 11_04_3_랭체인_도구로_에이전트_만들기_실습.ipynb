{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Antique-1/llm-programming1/blob/main/11_04_3_%EB%9E%AD%EC%B2%B4%EC%9D%B8_%EB%8F%84%EA%B5%AC%EB%A1%9C_%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8_%EB%A7%8C%EB%93%A4%EA%B8%B0_%EC%8B%A4%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "vCoxbX3jpFmH"
      },
      "cell_type": "markdown",
      "source": [
        "# 랭체인 도구로 에이전트 만들기\n",
        "- LangChain에서 도구를 정의하고 사용하는 방법 확인\n",
        "- LLM이 스스로 도구가 필요하다고 판단하고 도구 실행을 요청하는 과정 확인\n",
        "- 모델 호출 -> 도구 실행 -> 모델 재호출"
      ]
    },
    {
      "metadata": {
        "id": "nErYHUvopFmI"
      },
      "cell_type": "markdown",
      "source": [
        "## 라이브러리 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install langchain langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi6e9HTepctq",
        "outputId": "ac08e999-afdc-4070-e42d-20f35a3bb29d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-1.0.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.79)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.38)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_openai-1.0.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading langchain_openai-1.0.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.12.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Downloading langchain_openai-0.3.35-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain_openai\n",
            "Successfully installed langchain_openai-0.3.35\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-03T19:01:45.860693Z",
          "start_time": "2025-11-03T19:01:45.421947Z"
        },
        "id": "W6AmTtYMpFmJ"
      },
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage"
      ],
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = \"\""
      ],
      "metadata": {
        "id": "yrQlZczcpag-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dBV6G1f-pFmJ"
      },
      "cell_type": "markdown",
      "source": [
        "## API KEY 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-03T19:01:47.750511Z",
          "start_time": "2025-11-03T19:01:46.686255Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crJpyf5YpFmJ",
        "outputId": "47a223de-50ef-4297-a2df-4788ef686efd"
      },
      "source": [
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    api_key = api_key\n",
        "    )\n",
        "llm.invoke([HumanMessage(\"잘 지냈어?\")])"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='네, 잘 지냈습니다! 당신은 어떻게 지내고 계세요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 12, 'total_tokens': 28, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CY0sZncWC1hVWqtt5JCSsteEzCWIX', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--7836d3af-882a-4470-a556-74c6355874a4-0', usage_metadata={'input_tokens': 12, 'output_tokens': 16, 'total_tokens': 28, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "execution_count": 4
    },
    {
      "metadata": {
        "id": "iBrL_buOpFmK"
      },
      "cell_type": "markdown",
      "source": [
        "## 도구 정의\n",
        "- `@tool` : 이 데코레이터를 파이썬 함수 위에 붙이면 LangChain이 이 함수를 LLM이 사용할 수 있는 도구로 반환함\n",
        "- `dogString`\n",
        "  - LLM이 docstring을 읽고 이 도구가 무슨 일을 하는지, 언제 이 도구를 사용해야 하는지 등 판단\n",
        "  - `Args`: LLM이 timezone과 location에 어떤 값을 넣어야 할지 결정하는 데 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-03T19:01:57.439054Z",
          "start_time": "2025-11-03T19:01:57.429184Z"
        },
        "id": "ipxcrOHzpFmK"
      },
      "source": [
        "from langchain_core.tools import tool\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "@tool # @tool 데코레이터를 사용하여 함수를 도구로 등록\n",
        "def get_current_time(timezone: str, location: str) -> str:\n",
        "    \"\"\" 현재 시각을 반환하는 함수\n",
        "\n",
        "    Args:\n",
        "        timezone (str): 타임존 (예: 'Asia/Seoul') 실제 존재하는 타임존이어야 함\n",
        "        location (str): 지역명. 타임존이 모든 지명에 대응되지 않기 때문에 이후 llm 답변 생성에 사용됨\n",
        "    \"\"\"\n",
        "    tz = pytz.timezone(timezone)\n",
        "    now = datetime.now(tz).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    location_and_local_time = f'{timezone} ({location}) 현재시각 {now} ' # 타임존, 지역명, 현재시각을 문자열로 반환\n",
        "    print(location_and_local_time)\n",
        "    return location_and_local_time\n"
      ],
      "outputs": [],
      "execution_count": 5
    },
    {
      "metadata": {
        "id": "PJVdOpWApFmK"
      },
      "cell_type": "markdown",
      "source": [
        "## 모델에 도구 바인딩\n",
        "- llm_with_tools 객체는 이제 도구를 사용할지 말지 스스로 결정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-03T19:02:00.737299Z",
          "start_time": "2025-11-03T19:02:00.733112Z"
        },
        "id": "QtjeHOMUpFmK"
      },
      "source": [
        "# 도구를 tools 리스트에 추가하고, tool_dict에도 추가\n",
        "tools = [get_current_time,]\n",
        "tool_dict = {\"get_current_time\": get_current_time,}\n",
        "\n",
        "# 도구를 모델에 바인딩: 모델에 도구를 바인딩하면, 도구를 사용하여 llm 답변을 생성할 수 있음\n",
        "llm_with_tools = llm.bind_tools(tools)"
      ],
      "outputs": [],
      "execution_count": 6
    },
    {
      "metadata": {
        "id": "99hzhoibpFmL"
      },
      "cell_type": "markdown",
      "source": [
        "## 1단계 : 모델의 도구 호출 결정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-03T19:05:26.369161Z",
          "start_time": "2025-11-03T19:05:25.063959Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2lqF-hYpFmL",
        "outputId": "ff68e8b5-2516-465f-d249-330466b5dae4"
      },
      "source": [
        "from langchain_core.messages import SystemMessage\n",
        "\n",
        "# 사용자의 질문과 tools 사용하여 llm 답변 생성\n",
        "messages = [\n",
        "    SystemMessage(\"너는 사용자의 질문에 답변을 하기 위해 tools를 사용할 수 있다.\"),\n",
        "    HumanMessage(\"부산은 지금 몇시야?\"),\n",
        "]\n",
        "\n",
        "# llm_with_tools를 사용하여 사용자의 질문에 대한 llm 답변 생성\n",
        "response = llm_with_tools.invoke(messages)\n",
        "messages.append(response)\n",
        "\n",
        "# 생성된 llm 답변 출력\n",
        "print(messages)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SystemMessage(content='너는 사용자의 질문에 답변을 하기 위해 tools를 사용할 수 있다.', additional_kwargs={}, response_metadata={}), HumanMessage(content='부산은 지금 몇시야?', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_CGTT7yf5HGAyv6KasS7nTcym', 'function': {'arguments': '{\"timezone\":\"Asia/Seoul\",\"location\":\"부산\"}', 'name': 'get_current_time'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 135, 'total_tokens': 158, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CY0skMH9Y9WNgWhVV22eJjO0CQWYl', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--6a5ed908-6a1b-436b-a585-90586ccd1a6e-0', tool_calls=[{'name': 'get_current_time', 'args': {'timezone': 'Asia/Seoul', 'location': '부산'}, 'id': 'call_CGTT7yf5HGAyv6KasS7nTcym', 'type': 'tool_call'}], usage_metadata={'input_tokens': 135, 'output_tokens': 23, 'total_tokens': 158, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "metadata": {
        "id": "rtE6KSeBpFmL"
      },
      "cell_type": "markdown",
      "source": [
        "### 문제 2)\n",
        "lm_with_tools 모델이 가장 처음 반환한 AIMessage에 포함된 핵심 정보는?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "모델이 사용해야 할 랭체인 도구의 정보가 들어있음"
      ],
      "metadata": {
        "id": "O60-HVyyqImW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-rhha3gtpFmL"
      },
      "cell_type": "markdown",
      "source": [
        "## 2단계 : 도구 실행\n",
        "- 실제 랭체인 사용 시에는 LangChain 프레임워크가 이 1~3단계를 랭체인 에이전트로 자동화함\n",
        "- `AgentExecutor`에 도구가 바인딩된 LLM과 실제 실행할 도구 목록만 전달해주면 됨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-03T19:05:30.545267Z",
          "start_time": "2025-11-03T19:05:30.520323Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05zTyH5SpFmL",
        "outputId": "74715414-918d-4d14-8e15-122dda9cf48c"
      },
      "source": [
        "for tool_call in response.tool_calls:\n",
        "    selected_tool = tool_dict[tool_call[\"name\"]] # tool_dict를 사용하여 도구 함수를 선택\n",
        "    print(tool_call[\"args\"]) # 도구 호출 시 전달된 인자 출력\n",
        "    tool_msg = selected_tool.invoke(tool_call) # 도구 함수를 호출하여 결과를 반환\n",
        "    messages.append(tool_msg)\n",
        "\n",
        "messages"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'timezone': 'Asia/Seoul', 'location': '부산'}\n",
            "Asia/Seoul (부산) 현재시각 2025-11-04 11:16:21 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='너는 사용자의 질문에 답변을 하기 위해 tools를 사용할 수 있다.', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='부산은 지금 몇시야?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_CGTT7yf5HGAyv6KasS7nTcym', 'function': {'arguments': '{\"timezone\":\"Asia/Seoul\",\"location\":\"부산\"}', 'name': 'get_current_time'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 135, 'total_tokens': 158, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CY0skMH9Y9WNgWhVV22eJjO0CQWYl', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--6a5ed908-6a1b-436b-a585-90586ccd1a6e-0', tool_calls=[{'name': 'get_current_time', 'args': {'timezone': 'Asia/Seoul', 'location': '부산'}, 'id': 'call_CGTT7yf5HGAyv6KasS7nTcym', 'type': 'tool_call'}], usage_metadata={'input_tokens': 135, 'output_tokens': 23, 'total_tokens': 158, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              " ToolMessage(content='Asia/Seoul (부산) 현재시각 2025-11-04 11:16:21 ', name='get_current_time', tool_call_id='call_CGTT7yf5HGAyv6KasS7nTcym')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "execution_count": 8
    },
    {
      "metadata": {
        "id": "KkOtHQZYpFmM"
      },
      "cell_type": "markdown",
      "source": [
        "## 3단계 : 모델의 최종 답변"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-03T19:05:48.252423Z",
          "start_time": "2025-11-03T19:05:46.839088Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IN7H3jO9pFmM",
        "outputId": "f85b62ed-f610-41e3-820b-f38741dcb258"
      },
      "source": [
        "llm_with_tools.invoke(messages)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='부산은 지금 2025년 11월 4일 오전 11시 16분입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 192, 'total_tokens': 216, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CY0sqn2Y8cJajhLenNmNrL8GugZi1', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--993e3c51-c669-4a30-81c4-c0be20fffee2-0', usage_metadata={'input_tokens': 192, 'output_tokens': 24, 'total_tokens': 216, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "execution_count": 9
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}